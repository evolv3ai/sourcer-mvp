# Story 2.1: Enable Voice Query Input via STT

## Status: Approved

## Story

-   As an AI Enthusiast,
-   I want to use my voice to ask a question,
-   so that I can interact with Sourcer hands-free.

## Acceptance Criteria (ACs)

1.  The application can capture audio input from the default system microphone when voice input is activated by the user.
2.  User-initiated voice input (via the `MicrophoneActivationControl` as defined in the UI/UX Spec) is processed by the system.
3.  Spoken words are transcribed into text by a local STT engine (Vosk, integrated via Pipecat as per Architecture).
4.  The fully transcribed text of the user's query is displayed in the `ChatLogWidget`.
5.  The UI's `MicrophoneStatusIndicator` accurately reflects the current state of voice input (e.g., Idle, Listening, Processing STT, Error) as defined in the UI/UX Spec.
6.  STT processing latency is minimized to maintain a responsive user experience.
7.  Partial transcriptions may optionally be displayed in the UI during voice input for better user feedback, if supported by Pipecat and deemed feasible for MVP.

## Tasks / Subtasks

-   [ ] **Task 1: Implement `STTService` using Pipecat (AC: 1, 3, 6)**
    -   [ ] Create/Update `src/sourcer/services/stt_service.py`.
    -   [ ] Define an `STTService` class to manage Pipecat integration for Speech-to-Text.
    -   [ ] Configure Pipecat to use a local STT transport (e.g., Vosk, as specified in the Architecture Document). Ensure the Vosk model is downloaded/accessible (refer to Story 1.0 and `scripts/download_models.py`).
    -   [ ] Implement methods in `STTService` to:
        -   [ ] `start_transcription()`: Initializes Pipecat's STT pipeline, starts microphone audio capture through Pipecat.
        -   [ ] `stop_transcription()`: Stops Pipecat's STT pipeline and audio capture.
    -   [ ] Implement Pipecat event handlers within `STTService` for:
        -   `on_transcription_start`: To signal the system/UI that listening has actively started.
        -   `on_transcription_interim`: (Optional for AC7) To receive partial transcriptions.
        -   `on_transcription_end`: To receive the final transcribed text.
        -   `on_error`: To handle errors from the Pipecat STT pipeline.
    -   [ ] Define Qt signals in `STTService` (or use callbacks) to communicate transcription events (start, interim text, final text, error) to the `CoreOrchestrator` or UI.
-   [ ] **Task 2: Integrate `STTService` with `CoreOrchestrator` (AC: 2, 3, 4, 5)**
    -   [ ] In `src/sourcer/core/orchestrator.py`:
        -   [ ] Instantiate `STTService`.
        -   [ ] Implement methods to be called by the UI (e.g., via `MainWindow`) when the `MicrophoneActivationControl` is used:
            -   `handle_start_voice_input()`: Calls `STTService.start_transcription()`, updates internal state, signals UI to change `MicrophoneStatusIndicator` to 'Listening'.
            -   `handle_stop_voice_input()`: Calls `STTService.stop_transcription()`, updates internal state, signals UI to change `MicrophoneStatusIndicator` to 'Idle' or 'Processing STT' briefly.
        -   [ ] Connect to signals/callbacks from `STTService`:
            -   On receiving final transcription: Pass it to a new method (e.g., `process_transcribed_query(text)`) which will (in future stories) trigger vision analysis. For this story, ensure it signals the UI to display the query in the `ChatLogWidget`.
            -   On receiving interim transcription (if AC7 implemented): Signal UI to display interim text.
            -   On STT error: Log error, signal UI to show error status and message.
-   [ ] **Task 3: Update UI for Voice Input Control and Feedback (AC: 2, 4, 5, 7)**
    -   [ ] In `src/sourcer/ui/main_window.py` (and/or `InputControlWidget` if it's a separate class):
        -   [ ] Connect the `MicrophoneActivationControl` button's clicked signal to the `CoreOrchestrator`'s `handle_start_voice_input()` / `handle_stop_voice_input()` methods (logic might be needed to toggle).
    -   [ ] Implement logic in `MainWindow` or relevant UI components to update the `MicrophoneStatusIndicator` based on signals from `CoreOrchestrator` (Idle, Listening, Processing STT, Error).
    -   [ ] Implement logic in `MainWindow` or `ChatLogWidget` to display the final transcribed query (and optional interim transcriptions) in the chat/log area, attributed to the user.
-   [ ] **Task 4: Implement Basic Error Handling for STT (AC: 5)**
    -   [ ] Ensure `STTService` and `CoreOrchestrator` can handle and report common STT errors (e.g., microphone access denied by OS if Pipecat doesn't handle it abstractly, STT model load failure, Pipecat service error).
    -   [ ] Ensure the UI displays a user-friendly error message in the `ChatLogWidget` or a status area if STT fails.

## Dev Technical Guidance

-   **Pipecat Integration:** This is the core of the task. The developer agent needs to understand how to set up a simple Pipecat application, configure it for local STT (Vosk), manage the audio input stream, and handle transcription events. Refer to Pipecat documentation[cite: 284].
-   **Threading for Pipecat:** Pipecat services typically run in their own threads or use asyncio. Ensure that interactions between Pipecat (potentially running in a separate thread/async loop managed by `STTService`) and the PyQt UI (main thread) are thread-safe, using Qt signals and slots for cross-thread communication.
-   **UI Updates:**
    -   The `MicrophoneActivationControl` (likely a `QPushButton`) state should toggle between "Start Listening" and "Stop Listening" (or visually indicate this).
    -   The `MicrophoneStatusIndicator` (as described in UI/UX Spec) is key for user feedback.
    -   Transcribed text should be appended to the `ChatLogWidget` (e.g., a `QTextBrowser` or `QListWidget`).
-   **Configuration:** The `STTService` should load STT model configurations (e.g., path to Vosk model) from `config/settings.ini` via the `ConfigLoader` utility.
-   **Error Handling:** Focus on graceful degradation. If STT fails, the user should be informed, and text input should still be available.
-   **Modularity:** Keep Pipecat-specific logic encapsulated within the `STTService`. The `CoreOrchestrator` should interact with a cleaner interface provided by `STTService`.

## Story Progress Notes

### Agent Model Used: `<Agent Model Name/Version>`

### Completion Notes List
{Any notes about implementation choices, difficulties, or follow-up needed}

### Change Log