# Story 5.1: Implement Voice Input Activation Control

## Status: Approved

## Story

-   As an AI Enthusiast,
-   I want a button or mechanism to explicitly trigger voice input listening,
-   so that I have control over when the microphone is active.

## Acceptance Criteria (ACs)

1.  A `QPushButton` (or equivalent clickable UI element) serving as the `MicrophoneActivationControl` is implemented and visibly placed within the `InputControlWidget` area of the main window, as per the UI/UX Specification.
2.  When the system is in an "Idle" state (not currently listening or processing a voice query) and the user clicks the `MicrophoneActivationControl`, the `CoreOrchestrator.handle_start_voice_input()` method is successfully invoked.
3.  When the system is in a "Listening" or "Processing STT" state (initiated by a previous click on the `MicrophoneActivationControl`) and the user clicks the `MicrophoneActivationControl` again, the `CoreOrchestrator.handle_stop_voice_input()` method is successfully invoked.
4.  The visual appearance of the `MicrophoneActivationControl` (e.g., icon, tooltip) and the `MicrophoneStatusIndicator` correctly updates to reflect the system's voice input state (Idle, Listening, Processing STT, Error) immediately following user interaction with the control and feedback from the `CoreOrchestrator` (leveraging UI update logic from Story 2.1).
5.  The `MicrophoneActivationControl` button has an appropriate tooltip (e.g., "Start Voice Query" / "Stop Voice Query" depending on state, or a generic "Activate Voice Query").

## Tasks / Subtasks

-   [ ] **Task 1: Implement `MicrophoneActivationControl` UI Element (AC: 1, 5)**
    -   [ ] In `src/sourcer/ui/main_window.py` or a dedicated `src/sourcer/ui/widgets/input_control_widget.py`:
        -   [ ] Create a `QPushButton` instance for the `MicrophoneActivationControl`.
        -   [ ] Style it with an appropriate icon (e.g., microphone symbol) and set its tooltip as per UI/UX Specification.
        -   [ ] Ensure it's correctly added to the layout of the `InputControlWidget` area.
        -   [ ] (If not already done in Story 2.1) Ensure the `MicrophoneStatusIndicator` (e.g., a QLabel or another icon-based widget) is also present and laid out correctly near the activation control.
-   [ ] **Task 2: Connect Control to `CoreOrchestrator` Logic (AC: 2, 3)**
    -   [ ] In `src/sourcer/ui/main_window.py` (or wherever the `InputControlWidget` and `CoreOrchestrator` instance are managed):
        -   [ ] Connect the `clicked` signal of the `MicrophoneActivationControl` button to a new handler method within the UI layer (e.g., `on_mic_button_clicked`).
        -   [ ] This handler method must:
            -   [ ] Check the current voice input state (e.g., by querying a status from `CoreOrchestrator` or maintaining a simple state variable in the UI that's updated by `CoreOrchestrator` signals from Story 2.1).
            -   [ ] If "Idle" or "Error", call `CoreOrchestrator.handle_start_voice_input()`.
            -   [ ] If "Listening" or "Processing STT", call `CoreOrchestrator.handle_stop_voice_input()`.
-   [ ] **Task 3: Ensure UI State Updates are Correctly Triggered (AC: 4)**
    -   [ ] Verify that the existing UI update logic (implemented in Story 2.1 for `MicrophoneStatusIndicator` based on `CoreOrchestrator` signals) correctly reflects state changes triggered by this new button.
    -   [ ] If the `MicrophoneActivationControl` button itself needs to change its appearance (e.g., icon changes from 'mic' to 'stop mic'), implement this visual state change within the UI layer, driven by the same signals from `CoreOrchestrator` that update the `MicrophoneStatusIndicator`.

## Dev Technical Guidance

-   **UI Element:** The `MicrophoneActivationControl` should be a standard `QPushButton`. Its visual styling (icon, flat appearance, tooltips) should align with the UI/UX Specification (`Sourcer-MVP-Wireframes-and-Mockups.txt` and `Sourcer-MVP-front-end-spec.txt`).
-   **State Management for Toggle:** The button effectively acts as a toggle. The UI handler (`on_mic_button_clicked`) needs to know the current voice input state to decide whether to call `handle_start_voice_input()` or `handle_stop_voice_input()` on the `CoreOrchestrator`. This state should be reliably sourced from or synchronized with the `CoreOrchestrator` (which should be the source of truth for the voice pipeline's state, as established in Story 2.1).
-   **Signal/Slot Connections:** Standard PyQt signal/slot mechanisms should be used to link the button click to the handler method in the UI, and then to call methods on the `CoreOrchestrator` instance.
-   **Re-using Existing Logic:** This story primarily focuses on wiring up the UI control. The core logic for starting/stopping STT via `STTService` and updating the `MicrophoneStatusIndicator` should already be in place within `CoreOrchestrator` and the UI from Story 2.1. This story makes that logic user-triggerable via the dedicated button.
-   **User Feedback:** Ensure immediate visual feedback when the button is clicked and when the voice input state actually changes (via updates to the button's appearance and the `MicrophoneStatusIndicator`).

## Story Progress Notes

### Agent Model Used: `<Agent Model Name/Version>`

### Completion Notes List
{Any notes about implementation choices, difficulties, or follow-up needed}

### Change Log